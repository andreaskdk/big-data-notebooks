{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word count\n",
    "\n",
    "Word count has been called the \"Hello World\" of big data. This makes sense because counting word occurences comes down to simple map and reduce operations. It turns out that suprisingly many of the more involved types of analysis we wish to perform on data can be broken down to operations very similar to word count.\n",
    "\n",
    "Let us start with a small dataset of Shakespear quotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespear_data=spark.sparkContext.parallelize([\"All that glitters is not gold\", \n",
    "                                     \"Love all, trust a few, do wrong to none\",\n",
    "                                    \"To be or not to be that is the question\",\n",
    "                                    \"my kingdom for a horse\",\n",
    "                                    \"the world is a stage\",\n",
    "                                    \"is this a dagger that I see before me\",\n",
    "                                    \"nothing will come of nothing\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Spark we can perform wordcount in very few lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('glitters', 1),\n",
       " ('is', 4),\n",
       " ('gold', 1),\n",
       " ('Love', 1),\n",
       " ('do', 1),\n",
       " ('none', 1),\n",
       " ('question', 1),\n",
       " ('world', 1),\n",
       " ('stage', 1),\n",
       " ('this', 1),\n",
       " ('before', 1),\n",
       " ('of', 1),\n",
       " ('All', 1),\n",
       " ('that', 3),\n",
       " ('not', 2),\n",
       " ('all,', 1),\n",
       " ('trust', 1),\n",
       " ('a', 4),\n",
       " ('few,', 1),\n",
       " ('wrong', 1),\n",
       " ('to', 2),\n",
       " ('To', 1),\n",
       " ('be', 2),\n",
       " ('or', 1),\n",
       " ('the', 2),\n",
       " ('my', 1),\n",
       " ('kingdom', 1),\n",
       " ('for', 1),\n",
       " ('horse', 1),\n",
       " ('dagger', 1),\n",
       " ('I', 1),\n",
       " ('see', 1),\n",
       " ('me', 1),\n",
       " ('nothing', 2),\n",
       " ('will', 1),\n",
       " ('come', 1)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespear_data.flatMap(lambda line: line.split(\" \")) \\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b) \\\n",
    "             .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a few more operations to sort the list of words by occurance and only retrieve the top ten words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 4),\n",
       " ('a', 4),\n",
       " ('that', 3),\n",
       " ('not', 2),\n",
       " ('to', 2),\n",
       " ('be', 2),\n",
       " ('the', 2),\n",
       " ('nothing', 2),\n",
       " ('glitters', 1),\n",
       " ('gold', 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespear_data.flatMap(lambda line: line.split(\" \")) \\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b) \\\n",
    "             .map(lambda x: (x[1], x)) \\\n",
    "             .sortByKey(False) \\\n",
    "             .map(lambda x: x[1]) \\\n",
    "             .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topWords(data, n=10):\n",
    "    return data.flatMap(lambda line: line.lower().split(\" \")) \\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b) \\\n",
    "             .map(lambda x: (x[1], x)) \\\n",
    "             .sortByKey(False) \\\n",
    "             .map(lambda x: x[1]) \\\n",
    "             .take(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nytaar=spark.sparkContext.textFile(\"gs://big-data-course-datasets/nytaar/\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('og', 2368),\n",
       " ('det', 1702),\n",
       " ('i', 1546),\n",
       " ('at', 1463),\n",
       " ('vi', 1450),\n",
       " ('er', 1300),\n",
       " ('', 1153),\n",
       " ('for', 1142),\n",
       " ('til', 985),\n",
       " ('de', 849),\n",
       " ('som', 847),\n",
       " ('har', 766)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topWords(nytaar, n=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to know the count of a specific word? For example what word has the higher count: \"prins\" (prince) or \"prinsesse\" (princess)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prins', 38), ('prinsesse', 16)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nytaar.flatMap(lambda line: line.lower().split(\" \")) \\\n",
    "             .filter(lambda x: x==\"prins\" or x==\"prinsesse\") \\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b) \\\n",
    "             .map(lambda x: (x[1], x)) \\\n",
    "             .sortByKey(False) \\\n",
    "             .map(lambda x: x[1]) \\\n",
    "             .take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}